{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RPBYlEVmpVt",
        "outputId": "2afc0ec8-671a-480e-a4f4-d708bc296339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "class ProductWriterAI:\n",
        "    def __init__(self):\n",
        "        device_id = 0 if torch.cuda.is_available() else -1\n",
        "        if device_id == 0:\n",
        "            print(\"GPU Enabled.\")\n",
        "\n",
        "        print(\"Loading models...\")\n",
        "\n",
        "        self.generator = pipeline(\"text-generation\", model=\"distilgpt2\", device=device_id)\n",
        "\n",
        "        self.ner = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\", device=device_id)\n",
        "\n",
        "        self.summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", device=device_id)\n",
        "\n",
        "        self.qa = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", device=device_id)\n",
        "\n",
        "    def create_marketing_package(self, product_name):\n",
        "\n",
        "        prompt = f\"The {product_name} is a premium solution designed to provide\"\n",
        "\n",
        "        generated = self.generator(\n",
        "            prompt,\n",
        "            max_new_tokens=60,\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.7,\n",
        "            repetition_penalty=1.3,\n",
        "            do_sample=True,\n",
        "            pad_token_id=50256\n",
        "        )\n",
        "\n",
        "        sales_pitch = generated[0]['generated_text']\n",
        "        if \".\" in sales_pitch:\n",
        "            sales_pitch = sales_pitch[:sales_pitch.rfind(\".\") + 1]\n",
        "\n",
        "        summary = self.summarizer(sales_pitch, max_length=15, min_length=5, do_sample=False)\n",
        "        tagline = summary[0]['summary_text']\n",
        "\n",
        "        entities = self.ner(sales_pitch)\n",
        "\n",
        "        question = \"What does this product provide?\"\n",
        "        answer = self.qa(question=question, context=sales_pitch)\n",
        "\n",
        "        return {\n",
        "            \"Product\": product_name,\n",
        "            \"Sales Pitch\": sales_pitch,\n",
        "            \"Tagline\": tagline,\n",
        "            \"Entities Detected\": entities,\n",
        "            \"FAQ\": answer['answer']\n",
        "        }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ai_marketer = ProductWriterAI()\n",
        "\n",
        "    product = input(\"\\nEnter a product name (e.g., Luxury Fountain Pen): \")\n",
        "    result = ai_marketer.create_marketing_package(product)\n",
        "\n",
        "    print(f\"\\n### Marketing Copy for: {result['Product']} ###\")\n",
        "    print(f\"\\n[Generated Pitch]\\n{result['Sales Pitch']}\")\n",
        "    print(f\"\\n[Generated Tagline]\\n{result['Tagline']}\")\n",
        "\n",
        "    print(f\"\\n[NER Extraction]\")\n",
        "    for entity in result['Entities Detected']:\n",
        "        print(f\"- {entity['word']} ({entity['entity_group']})\")\n",
        "\n",
        "    print(f\"\\n[Automated QA]\")\n",
        "    print(f\"Q: What is the main benefit?\\nA: {result['FAQ']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NprPXZznoA5",
        "outputId": "ae45446c-7e3e-473d-9077-98750365c41f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Enabled.\n",
            "Loading models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter a product name (e.g., Luxury Fountain Pen): Samsung phone\n",
            "\n",
            "### Marketing Copy for: Samsung phone ###\n",
            "\n",
            "[Generated Pitch]\n",
            "The Samsung phone is a premium solution designed to provide unparalleled security. It's the flagship smartphone of our smartphones, and we're excited about that as well!\n",
            "A Galaxy S6 edge with LTE support powered by Qualcomm Snapdragon 801 (8GB RAM) processor can be found at www://www-samsungappsstore/products.\n",
            "\n",
            "[Generated Tagline]\n",
            " Galaxy S6 edge with LTE support powered by Qualcomm Snapdragon 8\n",
            "\n",
            "[NER Extraction]\n",
            "- Samsung (ORG)\n",
            "- Galaxy S6 (MISC)\n",
            "- L (MISC)\n",
            "- Qualcomm Snapdragon (MISC)\n",
            "\n",
            "[Automated QA]\n",
            "Q: What is the main benefit?\n",
            "A: unparalleled security\n"
          ]
        }
      ]
    }
  ]
}
